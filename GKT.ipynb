{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GKT.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "inSjw5KUZoZ9"
      },
      "source": [
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "from torch.autograd import Variable\n",
        "import math\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SmYN-3rRzp3"
      },
      "source": [
        "def build_dense_graph(node_num):\n",
        "    graph = 1. / (node_num - 1) * np.ones((node_num, node_num))\n",
        "    np.fill_diagonal(graph, 0)\n",
        "    graph = torch.from_numpy(graph).float()\n",
        "    return graph\n",
        "\n",
        "\n",
        "def sample_gumbel(shape, eps=1e-10):\n",
        "    U = torch.rand(shape).float()\n",
        "    return - torch.log(eps - torch.log(U + eps))\n",
        "\n",
        "\n",
        "def gumbel_softmax_sample(logits, tau=1, eps=1e-10, dim=-1):\n",
        "    \"\"\"\n",
        "    NOTE: Stolen from https://github.com/ethanfetaya/NRI/blob/master/utils.py\n",
        "    Draw a sample from the Gumbel-Softmax distribution\n",
        "    based on\n",
        "    https://github.com/ericjang/gumbel-softmax/blob/3c8584924603869e90ca74ac20a6a03d99a91ef9/Categorical%20VAE.ipynb\n",
        "    \"\"\"\n",
        "    gumbel_noise = sample_gumbel(logits.size(), eps=eps)\n",
        "    if logits.is_cuda:\n",
        "        gumbel_noise = gumbel_noise.cuda()\n",
        "    y = logits + Variable(gumbel_noise)\n",
        "    return F.softmax(y / tau, dim=dim)\n",
        "\n",
        "\n",
        "def gumbel_softmax(logits, tau=1, hard=False, eps=1e-10, dim=-1):\n",
        "    \"\"\"\n",
        "    NOTE: Stolen from https://github.com/ethanfetaya/NRI/blob/master/utils.py\n",
        "    Sample from the Gumbel-Softmax distribution and optionally discretize.\n",
        "    Args:\n",
        "      logits: [batch_size, n_class] unnormalized log-probs\n",
        "      tau: non-negative scalar temperature\n",
        "      hard: if True, take argmax, but differentiate w.r.t. soft sample y\n",
        "    Returns:\n",
        "      [batch_size, n_class] sample from the Gumbel-Softmax distribution.\n",
        "      If hard=True, then the returned sample will be one-hot, otherwise it will\n",
        "      be a probability distribution that sums to 1 across classes\n",
        "    Constraints:\n",
        "    - this implementation only works on batch_size x num_features tensor for now\n",
        "    based on\n",
        "    https://github.com/ericjang/gumbel-softmax/blob/3c8584924603869e90ca74ac20a6a03d99a91ef9/Categorical%20VAE.ipynb\n",
        "    \"\"\"\n",
        "    y_soft = gumbel_softmax_sample(logits, tau=tau, eps=eps, dim=dim)\n",
        "    if hard:\n",
        "        shape = logits.size()\n",
        "        _, k = y_soft.data.max(-1)\n",
        "        # this bit is based on\n",
        "        # https://discuss.pytorch.org/t/stop-gradients-for-st-gumbel-softmax/530/5\n",
        "        y_hard = torch.zeros(*shape)\n",
        "        if y_soft.is_cuda:\n",
        "            y_hard = y_hard.cuda()\n",
        "        y_hard = y_hard.zero_().scatter_(-1, k.view(shape[:-1] + (1,)), 1.0)\n",
        "        # this cool bit of code achieves two things:\n",
        "        # - makes the output value exactly one-hot (since we add then\n",
        "        #   subtract y_soft value)\n",
        "        # - makes the gradient equal to y_soft gradient (since we strip\n",
        "        #   all other gradients)\n",
        "        y = Variable(y_hard - y_soft.data) + y_soft\n",
        "    else:\n",
        "        y = y_soft\n",
        "    return y\n",
        "\n",
        "\n",
        "def kl_categorical(preds, log_prior, concept_num, eps=1e-16):\n",
        "    kl_div = preds * (torch.log(preds + eps) - log_prior)\n",
        "    return kl_div.sum() / (concept_num * preds.size(0))\n",
        "\n",
        "\n",
        "def kl_categorical_uniform(preds, concept_num, num_edge_types, add_const=False, eps=1e-16):\n",
        "    kl_div = preds * torch.log(preds + eps)\n",
        "    if add_const:\n",
        "        const = np.log(num_edge_types)\n",
        "        kl_div += const\n",
        "    return kl_div.sum() / (concept_num * preds.size(0))\n",
        "\n",
        "\n",
        "def nll_gaussian(preds, target, variance, add_const=False):\n",
        "    # pred: [concept_num, embedding_dim]\n",
        "    # target: [concept_num, embedding_dim]\n",
        "    neg_log_p = ((preds - target) ** 2 / (2 * variance))\n",
        "    if add_const:\n",
        "        const = 0.5 * np.log(2 * np.pi * variance)\n",
        "        neg_log_p += const\n",
        "    return neg_log_p.mean()\n",
        "\n",
        "\n",
        "# Calculate accuracy of prediction result and its corresponding label\n",
        "# output: tensor, labels: tensor\n",
        "def accuracy(output, labels):\n",
        "    preds = output.max(1)[1].type_as(labels)\n",
        "    correct = preds.eq(labels.reshape(-1)).double()\n",
        "    correct = correct.sum()\n",
        "    return correct / len(labels)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4reECHeLzuq"
      },
      "source": [
        "class MLP(nn.Module):\n",
        "    \"\"\"Two-layer fully-connected ReLU net with batch norm.\"\"\"\n",
        "\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, dropout=0., bias=True):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim, bias=bias)\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim, bias=bias)\n",
        "        self.norm = nn.BatchNorm1d(output_dim)\n",
        "        # the paper said they added Batch Normalization for the output of MLPs, as shown in Section 4.2\n",
        "        self.dropout = dropout\n",
        "        self.output_dim = output_dim\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_normal_(m.weight.data)\n",
        "                m.bias.data.fill_(0.1)\n",
        "            elif isinstance(m, nn.BatchNorm1d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def batch_norm(self, inputs):\n",
        "        if inputs.numel() == self.output_dim or inputs.numel() == 0:\n",
        "            # batch_size == 1 or 0 will cause BatchNorm error, so return the input directly\n",
        "            return inputs\n",
        "        if len(inputs.size()) == 3:\n",
        "            x = inputs.view(inputs.size(0) * inputs.size(1), -1)\n",
        "            x = self.norm(x)\n",
        "            return x.view(inputs.size(0), inputs.size(1), -1)\n",
        "        else:  # len(input_size()) == 2\n",
        "            return self.norm(inputs)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        x = F.relu(self.fc1(inputs))\n",
        "        x = F.dropout(x, self.dropout, training=self.training)  # pay attention to add training=self.training\n",
        "        x = F.relu(self.fc2(x))\n",
        "        return self.batch_norm(x)\n",
        "\n",
        "\n",
        "class EraseAddGate(nn.Module):\n",
        "    \"\"\"\n",
        "    Erase & Add Gate module\n",
        "    NOTE: this erase & add gate is a bit different from that in DKVMN.\n",
        "    For more information about Erase & Add gate, please refer to the paper \"Dynamic Key-Value Memory Networks for Knowledge Tracing\"\n",
        "    The paper can be found in https://arxiv.org/abs/1611.08108\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, feature_dim, concept_num, bias=True):\n",
        "        super(EraseAddGate, self).__init__()\n",
        "        # weight\n",
        "        self.weight = nn.Parameter(torch.rand(concept_num))\n",
        "        self.reset_parameters()\n",
        "        # erase gate\n",
        "        self.erase = nn.Linear(feature_dim, feature_dim, bias=bias)\n",
        "        # add gate\n",
        "        self.add = nn.Linear(feature_dim, feature_dim, bias=bias)\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        stdv = 1. / math.sqrt(self.weight.size(0))\n",
        "        self.weight.data.uniform_(-stdv, stdv)\n",
        "\n",
        "    def forward(self, x):\n",
        "        r\"\"\"\n",
        "        Params:\n",
        "            x: input feature matrix\n",
        "        Shape:\n",
        "            x: [batch_size, concept_num, feature_dim]\n",
        "            res: [batch_size, concept_num, feature_dim]\n",
        "        Return:\n",
        "            res: returned feature matrix with old information erased and new information added\n",
        "        The GKT paper didn't provide detailed explanation about this erase-add gate. As the erase-add gate in the GKT only has one input parameter,\n",
        "        this gate is different with that of the DKVMN. We used the input matrix to build the erase and add gates, rather than $\\mathbf{v}_{t}$ vector in the DKVMN.\n",
        "        \"\"\"\n",
        "        erase_gate = torch.sigmoid(self.erase(x))  # [batch_size, concept_num, feature_dim]\n",
        "        # self.weight.unsqueeze(dim=1) shape: [concept_num, 1]\n",
        "        tmp_x = x - self.weight.unsqueeze(dim=1) * erase_gate * x\n",
        "        add_feat = torch.tanh(self.add(x))  # [batch_size, concept_num, feature_dim]\n",
        "        res = tmp_x + self.weight.unsqueeze(dim=1) * add_feat\n",
        "        return res\n",
        "\n",
        "\n",
        "class ScaledDotProductAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    Scaled Dot-Product Attention\n",
        "    NOTE: Stole and modify from https://github.com/jadore801120/attention-is-all-you-need-pytorch/blob/master/transformer/Modules.py\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, temperature, attn_dropout=0.):\n",
        "        super().__init__()\n",
        "        self.temperature = temperature\n",
        "        self.dropout = attn_dropout\n",
        "\n",
        "    def forward(self, q, k, mask=None):\n",
        "        r\"\"\"\n",
        "        Parameters:\n",
        "            q: multi-head query matrix\n",
        "            k: multi-head key matrix\n",
        "            mask: mask matrix\n",
        "        Shape:\n",
        "            q: [n_head, mask_num, embedding_dim]\n",
        "            k: [n_head, concept_num, embedding_dim]\n",
        "        Return: attention score of all queries\n",
        "        \"\"\"\n",
        "        attn = torch.matmul(q / self.temperature, k.transpose(1, 2))  # [n_head, mask_number, concept_num]\n",
        "        if mask is not None:\n",
        "            attn = attn.masked_fill(mask == 0, -1e9)\n",
        "        # pay attention to add training=self.training!\n",
        "        attn = F.dropout(F.softmax(attn, dim=0), self.dropout, training=self.training)  # pay attention that dim=-1 is not as good as dim=0!\n",
        "        return attn\n",
        "\n",
        "\n",
        "class MLPEncoder(nn.Module):\n",
        "    \"\"\"\n",
        "    MLP encoder module.\n",
        "    NOTE: Stole and modify the code from https://github.com/ethanfetaya/NRI/blob/master/modules.py\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, factor=True, dropout=0., bias=True):\n",
        "        super(MLPEncoder, self).__init__()\n",
        "        self.factor = factor\n",
        "        self.mlp = MLP(input_dim * 2, hidden_dim, hidden_dim, dropout=dropout, bias=bias)\n",
        "        self.mlp2 = MLP(hidden_dim, hidden_dim, hidden_dim, dropout=dropout, bias=bias)\n",
        "        if self.factor:\n",
        "            self.mlp3 = MLP(hidden_dim * 3, hidden_dim, hidden_dim, dropout=dropout, bias=bias)\n",
        "        else:\n",
        "            self.mlp3 = MLP(hidden_dim * 2, hidden_dim, hidden_dim, dropout=dropout, bias=bias)\n",
        "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_normal_(m.weight.data)\n",
        "                m.bias.data.fill_(0.1)\n",
        "\n",
        "    def node2edge(self, x, sp_send, sp_rec):\n",
        "        # NOTE: Assumes that we have the same graph across all samples.\n",
        "        receivers = torch.matmul(sp_rec, x)\n",
        "        senders = torch.matmul(sp_send, x)\n",
        "        edges = torch.cat([senders, receivers], dim=1)\n",
        "        return edges\n",
        "\n",
        "    def edge2node(self, x, sp_send_t, sp_rec_t):\n",
        "        # NOTE: Assumes that we have the same graph across all samples.\n",
        "        incoming = torch.matmul(sp_rec_t, x)\n",
        "        return incoming\n",
        "\n",
        "    def forward(self, inputs, sp_send, sp_rec, sp_send_t, sp_rec_t):\n",
        "        r\"\"\"\n",
        "        Parameters:\n",
        "            inputs: input concept embedding matrix\n",
        "            sp_send: one-hot encoded send-node index(sparse tensor)\n",
        "            sp_rec: one-hot encoded receive-node index(sparse tensor)\n",
        "            sp_send_t: one-hot encoded send-node index(sparse tensor, transpose)\n",
        "            sp_rec_t: one-hot encoded receive-node index(sparse tensor, transpose)\n",
        "        Shape:\n",
        "            inputs: [concept_num, embedding_dim]\n",
        "            sp_send: [edge_num, concept_num]\n",
        "            sp_rec: [edge_num, concept_num]\n",
        "            sp_send_t: [concept_num, edge_num]\n",
        "            sp_rec_t: [concept_num, edge_num]\n",
        "        Return:\n",
        "            output: [edge_num, edge_type_num]\n",
        "        \"\"\"\n",
        "        x = self.node2edge(inputs, sp_send, sp_rec)  # [edge_num, 2 * embedding_dim]\n",
        "        x = self.mlp(x)  # [edge_num, hidden_num]\n",
        "        x_skip = x\n",
        "\n",
        "        if self.factor:\n",
        "            x = self.edge2node(x, sp_send_t, sp_rec_t)  # [concept_num, hidden_num]\n",
        "            x = self.mlp2(x)  # [concept_num, hidden_num]\n",
        "            x = self.node2edge(x, sp_send, sp_rec)  # [edge_num, 2 * hidden_num]\n",
        "            x = torch.cat((x, x_skip), dim=1)  # Skip connection  shape: [edge_num, 3 * hidden_num]\n",
        "            x = self.mlp3(x)  # [edge_num, hidden_num]\n",
        "        else:\n",
        "            x = self.mlp2(x)  # [edge_num, hidden_num]\n",
        "            x = torch.cat((x, x_skip), dim=1)  # Skip connection  shape: [edge_num, 2 * hidden_num]\n",
        "            x = self.mlp3(x)  # [edge_num, hidden_num]\n",
        "        output = self.fc_out(x)  # [edge_num, output_dim]\n",
        "        return output\n",
        "\n",
        "\n",
        "class MLPDecoder(nn.Module):\n",
        "    \"\"\"\n",
        "    MLP decoder module.\n",
        "    NOTE: Stole and modify the code from https://github.com/ethanfetaya/NRI/blob/master/modules.py\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_dim, msg_hidden_dim, msg_output_dim, hidden_dim, edge_type_num, dropout=0., bias=True):\n",
        "        super(MLPDecoder, self).__init__()\n",
        "        self.msg_out_dim = msg_output_dim\n",
        "        self.edge_type_num = edge_type_num\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.msg_fc1 = nn.ModuleList([nn.Linear(2 * input_dim, msg_hidden_dim, bias=bias) for _ in range(edge_type_num)])\n",
        "        self.msg_fc2 = nn.ModuleList([nn.Linear(msg_hidden_dim, msg_output_dim, bias=bias) for _ in range(edge_type_num)])\n",
        "        self.out_fc1 = nn.Linear(msg_output_dim, hidden_dim, bias=bias)\n",
        "        self.out_fc2 = nn.Linear(hidden_dim, hidden_dim, bias=bias)\n",
        "        self.out_fc3 = nn.Linear(hidden_dim, input_dim, bias=bias)\n",
        "\n",
        "    def node2edge(self, x, sp_send, sp_rec):\n",
        "        receivers = torch.matmul(sp_rec, x)  # [edge_num, embedding_dim]\n",
        "        senders = torch.matmul(sp_send, x)  # [edge_num, embedding_dim]\n",
        "        edges = torch.cat([senders, receivers], dim=-1)  # [edge_num, 2 * embedding_dim]\n",
        "        return edges\n",
        "\n",
        "    def edge2node(self, x, sp_send_t, sp_rec_t):\n",
        "        # NOTE: Assumes that we have the same graph across all samples.\n",
        "        incoming = torch.matmul(sp_rec_t, x)\n",
        "        return incoming\n",
        "\n",
        "    def forward(self, inputs, rel_type, sp_send, sp_rec, sp_send_t, sp_rec_t):\n",
        "        r\"\"\"\n",
        "        Parameters:\n",
        "            inputs: input concept embedding matrix\n",
        "            rel_type: inferred edge weights for all edge types from MLPEncoder\n",
        "            sp_send: one-hot encoded send-node index(sparse tensor)\n",
        "            sp_rec: one-hot encoded receive-node index(sparse tensor)\n",
        "            sp_send_t: one-hot encoded send-node index(sparse tensor, transpose)\n",
        "            sp_rec_t: one-hot encoded receive-node index(sparse tensor, transpose)\n",
        "        Shape:\n",
        "            inputs: [concept_num, embedding_dim]\n",
        "            sp_send: [edge_num, concept_num]\n",
        "            sp_rec: [edge_num, concept_num]\n",
        "            sp_send_t: [concept_num, edge_num]\n",
        "            sp_rec_t: [concept_num, edge_num]\n",
        "        Return:\n",
        "            output: [edge_num, edge_type_num]\n",
        "        \"\"\"\n",
        "        # NOTE: Assumes that we have the same graph across all samples.\n",
        "        # Node2edge\n",
        "        pre_msg = self.node2edge(inputs, sp_send, sp_rec)\n",
        "        all_msgs = Variable(torch.zeros(pre_msg.size(0), self.msg_out_dim, device=inputs.device))  # [edge_num, msg_out_dim]\n",
        "        for i in range(self.edge_type_num):\n",
        "            msg = F.relu(self.msg_fc1[i](pre_msg))\n",
        "            msg = F.dropout(msg, self.dropout, training=self.training)\n",
        "            msg = F.relu(self.msg_fc2[i](msg))\n",
        "            msg = msg * rel_type[:, i:i + 1]\n",
        "            all_msgs += msg\n",
        "\n",
        "        # Aggregate all msgs to receiver\n",
        "        agg_msgs = self.edge2node(all_msgs, sp_send_t, sp_rec_t)  # [concept_num, msg_out_dim]\n",
        "        # Output MLP\n",
        "        pred = F.dropout(F.relu(self.out_fc1(agg_msgs)), self.dropout, training=self.training)  # [concept_num, hidden_dim]\n",
        "        pred = F.dropout(F.relu(self.out_fc2(pred)), self.dropout, training=self.training)  # [concept_num, hidden_dim]\n",
        "        pred = self.out_fc3(pred)  # [concept_num, embedding_dim]\n",
        "        return pred"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAUCfpmAQu8K"
      },
      "source": [
        "class GKT(nn.Module):\n",
        "\n",
        "    def __init__(self, concept_num, hidden_dim, embedding_dim, edge_type_num, graph_type, graph=None, graph_model=None, dropout=0.5, bias=True, binary=False, has_cuda=False):\n",
        "        super(GKT, self).__init__()\n",
        "        self.concept_num = concept_num\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.edge_type_num = edge_type_num\n",
        "\n",
        "        self.res_len = 2 if binary else 12\n",
        "        self.has_cuda = has_cuda\n",
        "\n",
        "        assert graph_type in ['Dense', 'Transition', 'DKT', 'PAM', 'MHA', 'VAE']\n",
        "        self.graph_type = graph_type\n",
        "        if graph_type in ['Dense', 'Transition', 'DKT']:\n",
        "            assert edge_type_num == 2\n",
        "            assert graph is not None and graph_model is None\n",
        "            self.graph = nn.Parameter(graph)  # [concept_num, concept_num]\n",
        "            self.graph.requires_grad = False  # fix parameter\n",
        "            self.graph_model = graph_model\n",
        "        else:  # ['PAM', 'MHA', 'VAE']\n",
        "            assert graph is None\n",
        "            self.graph = graph  # None\n",
        "            if graph_type == 'PAM':\n",
        "                assert graph_model is None\n",
        "                self.graph = nn.Parameter(torch.rand(concept_num, concept_num))\n",
        "            else:\n",
        "                assert graph_model is not None\n",
        "            self.graph_model = graph_model\n",
        "\n",
        "        # one-hot feature and question\n",
        "        one_hot_feat = torch.eye(self.res_len * self.concept_num)\n",
        "        self.one_hot_feat = one_hot_feat.cuda() if self.has_cuda else one_hot_feat\n",
        "        self.one_hot_q = torch.eye(self.concept_num, device=self.one_hot_feat.device)\n",
        "        zero_padding = torch.zeros(1, self.concept_num, device=self.one_hot_feat.device)\n",
        "        self.one_hot_q = torch.cat((self.one_hot_q, zero_padding), dim=0)\n",
        "        # concept and concept & response embeddings\n",
        "        self.emb_x = nn.Embedding(self.res_len * concept_num, embedding_dim)\n",
        "        # last embedding is used for padding, so dim + 1\n",
        "        self.emb_c = nn.Embedding(concept_num + 1, embedding_dim, padding_idx=-1)\n",
        "\n",
        "        # f_self function and f_neighbor functions\n",
        "        mlp_input_dim = hidden_dim + embedding_dim\n",
        "        self.f_self = MLP(mlp_input_dim, hidden_dim, hidden_dim, dropout=dropout, bias=bias)\n",
        "        self.f_neighbor_list = nn.ModuleList()\n",
        "        if graph_type in ['Dense', 'Transition', 'DKT', 'PAM']:\n",
        "            # f_in and f_out functions\n",
        "            self.f_neighbor_list.append(MLP(2 * mlp_input_dim, hidden_dim, hidden_dim, dropout=dropout, bias=bias))\n",
        "            self.f_neighbor_list.append(MLP(2 * mlp_input_dim, hidden_dim, hidden_dim, dropout=dropout, bias=bias))\n",
        "        else:  # ['MHA', 'VAE']\n",
        "            for i in range(edge_type_num):\n",
        "                self.f_neighbor_list.append(MLP(2 * mlp_input_dim, hidden_dim, hidden_dim, dropout=dropout, bias=bias))\n",
        "\n",
        "        # Erase & Add Gate\n",
        "        self.erase_add_gate = EraseAddGate(hidden_dim, concept_num)\n",
        "        # Gate Recurrent Unit\n",
        "        self.gru = nn.GRUCell(hidden_dim, hidden_dim, bias=bias)\n",
        "        # prediction layer\n",
        "        self.predict = nn.Linear(hidden_dim, 1, bias=bias)\n",
        "\n",
        "    # Aggregate step, as shown in Section 3.2.1 of the paper\n",
        "    def _aggregate(self, xt, qt, ht, batch_size):\n",
        "        r\"\"\"\n",
        "        Parameters:\n",
        "            xt: input one-hot question answering features at the current timestamp\n",
        "            qt: question indices for all students in a batch at the current timestamp\n",
        "            ht: hidden representations of all concepts at the current timestamp\n",
        "            batch_size: the size of a student batch\n",
        "        Shape:\n",
        "            xt: [batch_size]\n",
        "            qt: [batch_size]\n",
        "            ht: [batch_size, concept_num, hidden_dim]\n",
        "            tmp_ht: [batch_size, concept_num, hidden_dim + embedding_dim]\n",
        "        Return:\n",
        "            tmp_ht: aggregation results of concept hidden knowledge state and concept(& response) embedding\n",
        "        \"\"\"\n",
        "        qt_mask = torch.ne(qt, -1)  # [batch_size], qt != -1\n",
        "        x_idx_mat = torch.arange(self.res_len * self.concept_num, device=xt.device)\n",
        "        x_embedding = self.emb_x(x_idx_mat)  # [res_len * concept_num, embedding_dim]\n",
        "        masked_feat = F.embedding(xt[qt_mask], self.one_hot_feat)  # [mask_num, res_len * concept_num]\n",
        "        res_embedding = masked_feat.mm(x_embedding)  # [mask_num, embedding_dim]\n",
        "        mask_num = res_embedding.shape[0]\n",
        "\n",
        "        concept_idx_mat = self.concept_num * torch.ones((batch_size, self.concept_num), device=xt.device).long()\n",
        "        concept_idx_mat[qt_mask, :] = torch.arange(self.concept_num, device=xt.device)\n",
        "        concept_embedding = self.emb_c(concept_idx_mat)  # [batch_size, concept_num, embedding_dim]\n",
        "\n",
        "        index_tuple = (torch.arange(mask_num, device=xt.device), qt[qt_mask].long())\n",
        "        concept_embedding[qt_mask] = concept_embedding[qt_mask].index_put(index_tuple, res_embedding)\n",
        "        tmp_ht = torch.cat((ht, concept_embedding), dim=-1)  # [batch_size, concept_num, hidden_dim + embedding_dim]\n",
        "        return tmp_ht\n",
        "\n",
        "    # GNN aggregation step, as shown in 3.3.2 Equation 1 of the paper\n",
        "    def _agg_neighbors(self, tmp_ht, qt):\n",
        "        r\"\"\"\n",
        "        Parameters:\n",
        "            tmp_ht: temporal hidden representations of all concepts after the aggregate step\n",
        "            qt: question indices for all students in a batch at the current timestamp\n",
        "        Shape:\n",
        "            tmp_ht: [batch_size, concept_num, hidden_dim + embedding_dim]\n",
        "            qt: [batch_size]\n",
        "            m_next: [batch_size, concept_num, hidden_dim]\n",
        "        Return:\n",
        "            m_next: hidden representations of all concepts aggregating neighboring representations at the next timestamp\n",
        "            concept_embedding: input of VAE (optional)\n",
        "            rec_embedding: reconstructed input of VAE (optional)\n",
        "            z_prob: probability distribution of latent variable z in VAE (optional)\n",
        "        \"\"\"\n",
        "        qt_mask = torch.ne(qt, -1)  # [batch_size], qt != -1\n",
        "        masked_qt = qt[qt_mask]  # [mask_num, ]\n",
        "        masked_tmp_ht = tmp_ht[qt_mask]  # [mask_num, concept_num, hidden_dim + embedding_dim]\n",
        "        mask_num = masked_tmp_ht.shape[0]\n",
        "        self_index_tuple = (torch.arange(mask_num, device=qt.device), masked_qt.long())\n",
        "        self_ht = masked_tmp_ht[self_index_tuple]  # [mask_num, hidden_dim + embedding_dim]\n",
        "        self_features = self.f_self(self_ht)  # [mask_num, hidden_dim]\n",
        "        expanded_self_ht = self_ht.unsqueeze(dim=1).repeat(1, self.concept_num, 1)  #[mask_num, concept_num, hidden_dim + embedding_dim]\n",
        "        neigh_ht = torch.cat((expanded_self_ht, masked_tmp_ht), dim=-1)  #[mask_num, concept_num, 2 * (hidden_dim + embedding_dim)]\n",
        "        concept_embedding, rec_embedding, z_prob = None, None, None\n",
        "\n",
        "        if self.graph_type in ['Dense', 'Transition', 'DKT', 'PAM']:\n",
        "            adj = self.graph[masked_qt.long(), :].unsqueeze(dim=-1)  # [mask_num, concept_num, 1]\n",
        "            reverse_adj = self.graph[:, masked_qt.long()].transpose(0, 1).unsqueeze(dim=-1)  # [mask_num, concept_num, 1]\n",
        "            # self.f_neighbor_list[0](neigh_ht) shape: [mask_num, concept_num, hidden_dim]\n",
        "            neigh_features = adj * self.f_neighbor_list[0](neigh_ht) + reverse_adj * self.f_neighbor_list[1](neigh_ht)\n",
        "        else:  # ['MHA', 'VAE']\n",
        "            concept_index = torch.arange(self.concept_num, device=qt.device)\n",
        "            concept_embedding = self.emb_c(concept_index)  # [concept_num, embedding_dim]\n",
        "            if self.graph_type == 'MHA':\n",
        "                query = self.emb_c(masked_qt)\n",
        "                key = concept_embedding\n",
        "                att_mask = Variable(torch.ones(self.edge_type_num, mask_num, self.concept_num, device=qt.device))\n",
        "                for k in range(self.edge_type_num):\n",
        "                    index_tuple = (torch.arange(mask_num, device=qt.device), masked_qt.long())\n",
        "                    att_mask[k] = att_mask[k].index_put(index_tuple, torch.zeros(mask_num, device=qt.device))\n",
        "                graphs = self.graph_model(masked_qt, query, key, att_mask)\n",
        "            else:  # self.graph_type == 'VAE'\n",
        "                sp_send, sp_rec, sp_send_t, sp_rec_t = self._get_edges(masked_qt)\n",
        "                graphs, rec_embedding, z_prob = self.graph_model(concept_embedding, sp_send, sp_rec, sp_send_t, sp_rec_t)\n",
        "            neigh_features = 0\n",
        "            for k in range(self.edge_type_num):\n",
        "                adj = graphs[k][masked_qt, :].unsqueeze(dim=-1)  # [mask_num, concept_num, 1]\n",
        "                if k == 0:\n",
        "                    neigh_features = adj * self.f_neighbor_list[k](neigh_ht)\n",
        "                else:\n",
        "                    neigh_features = neigh_features + adj * self.f_neighbor_list[k](neigh_ht)\n",
        "            if self.graph_type == 'MHA':\n",
        "                neigh_features = 1. / self.edge_type_num * neigh_features\n",
        "        # neigh_features: [mask_num, concept_num, hidden_dim]\n",
        "        m_next = tmp_ht[:, :, :self.hidden_dim]\n",
        "        m_next[qt_mask] = neigh_features\n",
        "        m_next[qt_mask] = m_next[qt_mask].index_put(self_index_tuple, self_features)\n",
        "        return m_next, concept_embedding, rec_embedding, z_prob\n",
        "\n",
        "    # Update step, as shown in Section 3.3.2 of the paper\n",
        "    def _update(self, tmp_ht, ht, qt):\n",
        "        r\"\"\"\n",
        "        Parameters:\n",
        "            tmp_ht: temporal hidden representations of all concepts after the aggregate step\n",
        "            ht: hidden representations of all concepts at the current timestamp\n",
        "            qt: question indices for all students in a batch at the current timestamp\n",
        "        Shape:\n",
        "            tmp_ht: [batch_size, concept_num, hidden_dim + embedding_dim]\n",
        "            ht: [batch_size, concept_num, hidden_dim]\n",
        "            qt: [batch_size]\n",
        "            h_next: [batch_size, concept_num, hidden_dim]\n",
        "        Return:\n",
        "            h_next: hidden representations of all concepts at the next timestamp\n",
        "            concept_embedding: input of VAE (optional)\n",
        "            rec_embedding: reconstructed input of VAE (optional)\n",
        "            z_prob: probability distribution of latent variable z in VAE (optional)\n",
        "        \"\"\"\n",
        "        qt_mask = torch.ne(qt, -1)  # [batch_size], qt != -1\n",
        "        mask_num = qt_mask.nonzero().shape[0]\n",
        "        # GNN Aggregation\n",
        "        m_next, concept_embedding, rec_embedding, z_prob = self._agg_neighbors(tmp_ht, qt)  # [batch_size, concept_num, hidden_dim]\n",
        "        # Erase & Add Gate\n",
        "        m_next[qt_mask] = self.erase_add_gate(m_next[qt_mask])  # [mask_num, concept_num, hidden_dim]\n",
        "        # GRU\n",
        "        h_next = m_next\n",
        "        res = self.gru(m_next[qt_mask].reshape(-1, self.hidden_dim), ht[qt_mask].reshape(-1, self.hidden_dim))  # [mask_num * concept_num, hidden_num]\n",
        "        index_tuple = (torch.arange(mask_num, device=qt_mask.device), )\n",
        "        h_next[qt_mask] = h_next[qt_mask].index_put(index_tuple, res.reshape(-1, self.concept_num, self.hidden_dim))\n",
        "        return h_next, concept_embedding, rec_embedding, z_prob\n",
        "\n",
        "    # Predict step, as shown in Section 3.3.3 of the paper\n",
        "    def _predict(self, h_next, qt):\n",
        "        r\"\"\"\n",
        "        Parameters:\n",
        "            h_next: hidden representations of all concepts at the next timestamp after the update step\n",
        "            qt: question indices for all students in a batch at the current timestamp\n",
        "        Shape:\n",
        "            h_next: [batch_size, concept_num, hidden_dim]\n",
        "            qt: [batch_size]\n",
        "            y: [batch_size, concept_num]\n",
        "        Return:\n",
        "            y: predicted correct probability of all concepts at the next timestamp\n",
        "        \"\"\"\n",
        "        qt_mask = torch.ne(qt, -1)  # [batch_size], qt != -1\n",
        "        y = self.predict(h_next).squeeze(dim=-1)  # [batch_size, concept_num]\n",
        "        y[qt_mask] = torch.sigmoid(y[qt_mask])  # [batch_size, concept_num]\n",
        "        return y\n",
        "\n",
        "    def _get_next_pred(self, yt, q_next):\n",
        "        r\"\"\"\n",
        "        Parameters:\n",
        "            yt: predicted correct probability of all concepts at the next timestamp\n",
        "            q_next: question index matrix at the next timestamp\n",
        "            batch_size: the size of a student batch\n",
        "        Shape:\n",
        "            y: [batch_size, concept_num]\n",
        "            questions: [batch_size, seq_len]\n",
        "            pred: [batch_size, ]\n",
        "        Return:\n",
        "            pred: predicted correct probability of the question answered at the next timestamp\n",
        "        \"\"\"\n",
        "        next_qt = q_next\n",
        "        next_qt = torch.where(next_qt != -1, next_qt, self.concept_num * torch.ones_like(next_qt, device=yt.device))\n",
        "        one_hot_qt = F.embedding(next_qt.long(), self.one_hot_q)  # [batch_size, concept_num]\n",
        "        # dot product between yt and one_hot_qt\n",
        "        pred = (yt * one_hot_qt).sum(dim=1)  # [batch_size, ]\n",
        "        return pred\n",
        "\n",
        "    # Get edges for edge inference in VAE\n",
        "    def _get_edges(self, masked_qt):\n",
        "        r\"\"\"\n",
        "        Parameters:\n",
        "            masked_qt: qt index with -1 padding values removed\n",
        "        Shape:\n",
        "            masked_qt: [mask_num, ]\n",
        "            rel_send: [edge_num, concept_num]\n",
        "            rel_rec: [edge_num, concept_num]\n",
        "        Return:\n",
        "            rel_send: from nodes in edges which send messages to other nodes\n",
        "            rel_rec:  to nodes in edges which receive messages from other nodes\n",
        "        \"\"\"\n",
        "        mask_num = masked_qt.shape[0]\n",
        "        row_arr = masked_qt.cpu().numpy().reshape(-1, 1)  # [mask_num, 1]\n",
        "        row_arr = np.repeat(row_arr, self.concept_num, axis=1)  # [mask_num, concept_num]\n",
        "        col_arr = np.arange(self.concept_num).reshape(1, -1)  # [1, concept_num]\n",
        "        col_arr = np.repeat(col_arr, mask_num, axis=0)  # [mask_num, concept_num]\n",
        "        # add reversed edges\n",
        "        new_row = np.vstack((row_arr, col_arr))  # [2 * mask_num, concept_num]\n",
        "        new_col = np.vstack((col_arr, row_arr))  # [2 * mask_num, concept_num]\n",
        "        row_arr = new_row.flatten()  # [2 * mask_num * concept_num, ]\n",
        "        col_arr = new_col.flatten()  # [2 * mask_num * concept_num, ]\n",
        "        data_arr = np.ones(2 * mask_num * self.concept_num)\n",
        "        init_graph = sp.coo_matrix((data_arr, (row_arr, col_arr)), shape=(self.concept_num, self.concept_num))\n",
        "        init_graph.setdiag(0)  # remove self-loop edges\n",
        "        row_arr, col_arr, _ = sp.find(init_graph)\n",
        "        row_tensor = torch.from_numpy(row_arr).long()\n",
        "        col_tensor = torch.from_numpy(col_arr).long()\n",
        "        one_hot_table = torch.eye(self.concept_num, self.concept_num)\n",
        "        rel_send = F.embedding(row_tensor, one_hot_table)  # [edge_num, concept_num]\n",
        "        rel_rec = F.embedding(col_tensor, one_hot_table)  # [edge_num, concept_num]\n",
        "        sp_rec, sp_send = rel_rec.to_sparse(), rel_send.to_sparse()\n",
        "        sp_rec_t, sp_send_t = rel_rec.T.to_sparse(), rel_send.T.to_sparse()\n",
        "        sp_send = sp_send.to(device=masked_qt.device)\n",
        "        sp_rec = sp_rec.to(device=masked_qt.device)\n",
        "        sp_send_t = sp_send_t.to(device=masked_qt.device)\n",
        "        sp_rec_t = sp_rec_t.to(device=masked_qt.device)\n",
        "        return sp_send, sp_rec, sp_send_t, sp_rec_t\n",
        "\n",
        "    def forward(self, features, questions):\n",
        "        r\"\"\"\n",
        "        Parameters:\n",
        "            features: input one-hot matrix\n",
        "            questions: question index matrix\n",
        "        seq_len dimension needs padding, because different students may have learning sequences with different lengths.\n",
        "        Shape:\n",
        "            features: [batch_size, seq_len]\n",
        "            questions: [batch_size, seq_len]\n",
        "            pred_res: [batch_size, seq_len - 1]\n",
        "        Return:\n",
        "            pred_res: the correct probability of questions answered at the next timestamp\n",
        "            concept_embedding: input of VAE (optional)\n",
        "            rec_embedding: reconstructed input of VAE (optional)\n",
        "            z_prob: probability distribution of latent variable z in VAE (optional)\n",
        "        \"\"\"\n",
        "        batch_size, seq_len = features.shape\n",
        "        ht = Variable(torch.zeros((batch_size, self.concept_num, self.hidden_dim), device=features.device))\n",
        "        pred_list = []\n",
        "        ec_list = []  # concept embedding list in VAE\n",
        "        rec_list = []  # reconstructed embedding list in VAE\n",
        "        z_prob_list = []  # probability distribution of latent variable z in VAE\n",
        "        for i in range(seq_len):\n",
        "            xt = features[:, i]  # [batch_size]\n",
        "            qt = questions[:, i]  # [batch_size]\n",
        "            qt_mask = torch.ne(qt, -1)  # [batch_size], next_qt != -1\n",
        "            tmp_ht = self._aggregate(xt, qt, ht, batch_size)  # [batch_size, concept_num, hidden_dim + embedding_dim]\n",
        "            h_next, concept_embedding, rec_embedding, z_prob = self._update(tmp_ht, ht, qt)  # [batch_size, concept_num, hidden_dim]\n",
        "            ht[qt_mask] = h_next[qt_mask]  # update new ht\n",
        "            yt = self._predict(h_next, qt)  # [batch_size, concept_num]\n",
        "            if i < seq_len - 1:\n",
        "                pred = self._get_next_pred(yt, questions[:, i + 1])\n",
        "                pred_list.append(pred)\n",
        "            ec_list.append(concept_embedding)\n",
        "            rec_list.append(rec_embedding)\n",
        "            z_prob_list.append(z_prob)\n",
        "        pred_res = torch.stack(pred_list, dim=1)  # [batch_size, seq_len - 1]\n",
        "        return pred_res, ec_list, rec_list, z_prob_list"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAf_WhvokGes"
      },
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    Multi-Head Attention module\n",
        "    NOTE: Stole and modify from https://github.com/jadore801120/attention-is-all-you-need-pytorch/blob/master/transformer/SubLayers.py\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n_head, concept_num, input_dim, d_k, dropout=0.):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.n_head = n_head\n",
        "        self.concept_num = concept_num\n",
        "        self.d_k = d_k\n",
        "        self.w_qs = nn.Linear(input_dim, n_head * d_k, bias=False)\n",
        "        self.w_ks = nn.Linear(input_dim, n_head * d_k, bias=False)\n",
        "        self.attention = ScaledDotProductAttention(temperature=d_k ** 0.5, attn_dropout=dropout)\n",
        "        # inferred latent graph, used for saving and visualization\n",
        "        self.graphs = nn.Parameter(torch.zeros(n_head, concept_num, concept_num))\n",
        "        self.graphs.requires_grad = False\n",
        "\n",
        "    def _get_graph(self, attn_score, qt):\n",
        "        r\"\"\"\n",
        "        Parameters:\n",
        "            attn_score: attention score of all queries\n",
        "            qt: masked question index\n",
        "        Shape:\n",
        "            attn_score: [n_head, mask_num, concept_num]\n",
        "            qt: [mask_num]\n",
        "        Return:\n",
        "            graphs: n_head types of inferred graphs\n",
        "        \"\"\"\n",
        "        graphs = Variable(torch.zeros(self.n_head, self.concept_num, self.concept_num, device=qt.device))\n",
        "        for k in range(self.n_head):\n",
        "            index_tuple = (qt.long(), )\n",
        "            graphs[k] = graphs[k].index_put(index_tuple, attn_score[k])  # used for calculation\n",
        "            #############################\n",
        "            # here, we need to detach edges when storing it into self.graphs in case memory leak!\n",
        "            self.graphs.data[k] = self.graphs.data[k].index_put(index_tuple, attn_score[k].detach())  # used for saving and visualization\n",
        "            #############################\n",
        "        return graphs\n",
        "\n",
        "    def forward(self, qt, query, key, mask=None):\n",
        "        r\"\"\"\n",
        "        Parameters:\n",
        "            qt: masked question index\n",
        "            query: answered concept embedding for a student batch\n",
        "            key: concept embedding matrix\n",
        "            mask: mask matrix\n",
        "        Shape:\n",
        "            qt: [mask_num]\n",
        "            query: [mask_num, embedding_dim]\n",
        "            key: [concept_num, embedding_dim]\n",
        "        Return:\n",
        "            graphs: n_head types of inferred graphs\n",
        "        \"\"\"\n",
        "        d_k, n_head = self.d_k, self.n_head\n",
        "        len_q, len_k = query.size(0), key.size(0)\n",
        "\n",
        "        # Pass through the pre-attention projection: lq x (n_head *dk)\n",
        "        # Separate different heads: lq x n_head x dk\n",
        "        q = self.w_qs(query).view(len_q, n_head, d_k)\n",
        "        k = self.w_ks(key).view(len_k, n_head, d_k)\n",
        "\n",
        "        # Transpose for attention dot product: n_head x lq x dk\n",
        "        q, k = q.transpose(0, 1), k.transpose(0, 1)\n",
        "        attn_score = self.attention(q, k, mask=mask)  # [n_head, mask_num, concept_num]\n",
        "        graphs = self._get_graph(attn_score, qt)\n",
        "        return graphs"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcjAr9f8Q9Bk"
      },
      "source": [
        "class KTLoss(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(KTLoss, self).__init__()\n",
        "\n",
        "    def forward(self, pred_answers, real_answers):\n",
        "        r\"\"\"\n",
        "        Parameters:\n",
        "            pred_answers: the correct probability of questions answered at the next timestamp\n",
        "            real_answers: the real results(0 or 1) of questions answered at the next timestamp\n",
        "        Shape:\n",
        "            pred_answers: [batch_size, seq_len - 1]\n",
        "            real_answers: [batch_size, seq_len]\n",
        "        Return:\n",
        "        \"\"\"\n",
        "        real_answers = real_answers[:, 1:]  # timestamp=1 ~ T\n",
        "        # real_answers shape: [batch_size, seq_len - 1]\n",
        "        # Here we can directly use nn.BCELoss, but this loss doesn't have ignore_index function\n",
        "        answer_mask = torch.ne(real_answers, -1)\n",
        "        pred_one, pred_zero = pred_answers, 1.0 - pred_answers  # [batch_size, seq_len - 1]\n",
        "\n",
        "        # calculate auc and accuracy metrics\n",
        "        try:\n",
        "            y_true = real_answers[answer_mask].cpu().detach().numpy()\n",
        "            y_pred = pred_one[answer_mask].cpu().detach().numpy()\n",
        "            auc = roc_auc_score(y_true, y_pred)  # may raise ValueError\n",
        "            output = torch.cat((pred_zero[answer_mask].reshape(-1, 1), pred_one[answer_mask].reshape(-1, 1)), dim=1)\n",
        "            label = real_answers[answer_mask].reshape(-1, 1)\n",
        "            acc = accuracy(output, label)\n",
        "            acc = float(acc.cpu().detach().numpy())\n",
        "        except ValueError as e:\n",
        "            auc, acc = -1, -1\n",
        "\n",
        "        # calculate NLL loss\n",
        "        pred_one[answer_mask] = torch.log(pred_one[answer_mask])\n",
        "        pred_zero[answer_mask] = torch.log(pred_zero[answer_mask])\n",
        "        pred_answers = torch.cat((pred_zero.unsqueeze(dim=1), pred_one.unsqueeze(dim=1)), dim=1)\n",
        "        # pred_answers shape: [batch_size, 2, seq_len - 1]\n",
        "        nll_loss = nn.NLLLoss(ignore_index=-1)  # ignore masked values in real_answers\n",
        "        loss = nll_loss(pred_answers, real_answers.long())\n",
        "        return loss, auc, acc\n",
        "\n",
        "\n",
        "class VAELoss(nn.Module):\n",
        "\n",
        "    def __init__(self, concept_num, edge_type_num=2, prior=False, var=5e-5):\n",
        "        super(VAELoss, self).__init__()\n",
        "        self.concept_num = concept_num\n",
        "        self.edge_type_num = edge_type_num\n",
        "        self.prior = prior\n",
        "        self.var = var\n",
        "\n",
        "    def forward(self, ec_list, rec_list, z_prob_list, log_prior=None):\n",
        "        time_stamp_num = len(ec_list)\n",
        "        loss = 0\n",
        "        for time_idx in range(time_stamp_num):\n",
        "            output = rec_list[time_idx]\n",
        "            target = ec_list[time_idx]\n",
        "            prob = z_prob_list[time_idx]\n",
        "            loss_nll = nll_gaussian(output, target, self.var)\n",
        "            if self.prior:\n",
        "                assert log_prior is not None\n",
        "                loss_kl = kl_categorical(prob, log_prior, self.concept_num)\n",
        "            else:\n",
        "                loss_kl = kl_categorical_uniform(prob, self.concept_num, self.edge_type_num)\n",
        "            if time_idx == 0:\n",
        "                loss = loss_nll + loss_kl\n",
        "            else:\n",
        "                loss = loss + loss_nll + loss_kl\n",
        "        return loss / time_stamp_num"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVrrFKWCRYQd"
      },
      "source": [
        "import os\n",
        "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "class KTDataset(Dataset):\n",
        "    def __init__(self, features, questions, answers):\n",
        "        super(KTDataset, self).__init__()\n",
        "        self.features = features\n",
        "        self.questions = questions\n",
        "        self.answers = answers\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.features[index], self.questions[index], self.answers[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "\n",
        "def pad_collate(batch):\n",
        "    (features, questions, answers) = zip(*batch)\n",
        "    features = [torch.LongTensor(feat) for feat in features]\n",
        "    questions = [torch.LongTensor(qt) for qt in questions]\n",
        "    answers = [torch.LongTensor(ans) for ans in answers]\n",
        "    feature_pad = pad_sequence(features, batch_first=True, padding_value=-1)\n",
        "    question_pad = pad_sequence(questions, batch_first=True, padding_value=-1)\n",
        "    answer_pad = pad_sequence(answers, batch_first=True, padding_value=-1)\n",
        "    return feature_pad, question_pad, answer_pad\n",
        "\n",
        "\n",
        "def load_dataset(file_path, batch_size, graph_type, dkt_graph_path=None, train_ratio=0.7, val_ratio=0.2, shuffle=True, model_type='GKT', use_binary=True, res_len=2, use_cuda=True):\n",
        "    r\"\"\"\n",
        "    Parameters:\n",
        "        file_path: input file path of knowledge tracing data\n",
        "        batch_size: the size of a student batch\n",
        "        graph_type: the type of the concept graph\n",
        "        shuffle: whether to shuffle the dataset or not\n",
        "        use_cuda: whether to use GPU to accelerate training speed\n",
        "    Return:\n",
        "        concept_num: the number of all concepts(or questions)\n",
        "        graph: the static graph is graph type is in ['Dense', 'Transition', 'DKT'], otherwise graph is None\n",
        "        train_data_loader: data loader of the training dataset\n",
        "        valid_data_loader: data loader of the validation dataset\n",
        "        test_data_loader: data loader of the test dataset\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(file_path)\n",
        "    if \"skill_id\" not in df.columns:\n",
        "        raise KeyError(f\"The column 'skill_id' was not found on {file_path}\")\n",
        "    if \"correct\" not in df.columns:\n",
        "        raise KeyError(f\"The column 'correct' was not found on {file_path}\")\n",
        "    if \"user_id\" not in df.columns:\n",
        "        raise KeyError(f\"The column 'user_id' was not found on {file_path}\")\n",
        "\n",
        "    # if not (df['correct'].isin([0, 1])).all():\n",
        "    #     raise KeyError(f\"The values of the column 'correct' must be 0 or 1.\")\n",
        "\n",
        "    # Step 1.1 - Remove questions without skill\n",
        "    df.dropna(subset=['skill_id'], inplace=True)\n",
        "\n",
        "    # Step 1.2 - Remove users with a single answer\n",
        "    df = df.groupby('user_id').filter(lambda q: len(q) > 1).copy()\n",
        "\n",
        "    # Step 2 - Enumerate skill id\n",
        "    df['skill'], _ = pd.factorize(df['skill_id'], sort=True)  # we can also use problem_id to represent exercises\n",
        "\n",
        "    # Step 3 - Cross skill id with answer to form a synthetic feature\n",
        "    # use_binary: (0,1); !use_binary: (1,2,3,4,5,6,7,8,9,10,11,12). Either way, the correct result index is guaranteed to be 1\n",
        "    if use_binary:\n",
        "        df['skill_with_answer'] = df['skill'] * 2 + df['correct']\n",
        "    else:\n",
        "        df['skill_with_answer'] = df['skill'] * res_len + df['correct'] - 1\n",
        "\n",
        "\n",
        "    # Step 4 - Convert to a sequence per user id and shift features 1 timestep\n",
        "    feature_list = []\n",
        "    question_list = []\n",
        "    answer_list = []\n",
        "    seq_len_list = []\n",
        "\n",
        "    def get_data(series):\n",
        "        feature_list.append(series['skill_with_answer'].tolist())\n",
        "        question_list.append(series['skill'].tolist())\n",
        "        answer_list.append(series['correct'].eq(1).astype('int').tolist())\n",
        "        seq_len_list.append(series['correct'].shape[0])\n",
        "\n",
        "    df.groupby('user_id').apply(get_data)\n",
        "    max_seq_len = np.max(seq_len_list)\n",
        "    print('max seq_len: ', max_seq_len)\n",
        "    student_num = len(seq_len_list)\n",
        "    print('student num: ', student_num)\n",
        "    feature_dim = int(df['skill_with_answer'].max() + 1)\n",
        "    print('feature_dim: ', feature_dim)\n",
        "    question_dim = int(df['skill'].max() + 1)\n",
        "    print('question_dim: ', question_dim)\n",
        "    concept_num = question_dim\n",
        "\n",
        "    # print('feature_dim:', feature_dim, 'res_len*question_dim:', res_len*question_dim)\n",
        "    # assert feature_dim == res_len * question_dim\n",
        "\n",
        "    kt_dataset = KTDataset(feature_list, question_list, answer_list)\n",
        "    train_size = int(train_ratio * student_num)\n",
        "    val_size = int(val_ratio * student_num)\n",
        "    test_size = student_num - train_size - val_size\n",
        "    train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(kt_dataset, [train_size, val_size, test_size])\n",
        "    print('train_size: ', train_size, 'val_size: ', val_size, 'test_size: ', test_size)\n",
        "\n",
        "    train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle, collate_fn=pad_collate)\n",
        "    valid_data_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=shuffle, collate_fn=pad_collate)\n",
        "    test_data_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=shuffle, collate_fn=pad_collate)\n",
        "\n",
        "    graph = None\n",
        "    if model_type == 'GKT':\n",
        "        if graph_type == 'Dense':\n",
        "            graph = build_dense_graph(concept_num)\n",
        "        elif graph_type == 'Transition':\n",
        "            graph = build_transition_graph(question_list, seq_len_list, train_dataset.indices, student_num, concept_num)\n",
        "        elif graph_type == 'DKT':\n",
        "            graph = build_dkt_graph(dkt_graph_path, concept_num)\n",
        "        if use_cuda and graph_type in ['Dense', 'Transition', 'DKT']:\n",
        "            graph = graph.cuda()\n",
        "    return concept_num, graph, train_data_loader, valid_data_loader, test_data_loader\n",
        "\n",
        "\n",
        "def build_transition_graph(question_list, seq_len_list, indices, student_num, concept_num):\n",
        "    graph = np.zeros((concept_num, concept_num))\n",
        "    student_dict = dict(zip(indices, np.arange(student_num)))\n",
        "    for i in range(student_num):\n",
        "        if i not in student_dict:\n",
        "            continue\n",
        "        questions = question_list[i]\n",
        "        seq_len = seq_len_list[i]\n",
        "        for j in range(seq_len - 1):\n",
        "            pre = questions[j]\n",
        "            next = questions[j + 1]\n",
        "            graph[pre, next] += 1\n",
        "    np.fill_diagonal(graph, 0)\n",
        "    # row normalization\n",
        "    rowsum = np.array(graph.sum(1))\n",
        "    def inv(x):\n",
        "        if x == 0:\n",
        "            return x\n",
        "        return 1. / x\n",
        "    inv_func = np.vectorize(inv)\n",
        "    r_inv = inv_func(rowsum).flatten()\n",
        "    r_mat_inv = np.diag(r_inv)\n",
        "    graph = r_mat_inv.dot(graph)\n",
        "    # covert to tensor\n",
        "    graph = torch.from_numpy(graph).float()\n",
        "    return graph\n",
        "\n",
        "\n",
        "def build_dkt_graph(file_path, concept_num):\n",
        "    graph = np.loadtxt(file_path)\n",
        "    assert graph.shape[0] == concept_num and graph.shape[1] == concept_num\n",
        "    graph = torch.from_numpy(graph).float()\n",
        "    return graph"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnNXaziiSmlp"
      },
      "source": [
        "args = {\n",
        "    'seed':42,\n",
        "    'data-dir': '/content/drive/MyDrive/GKT-data',\n",
        "    'data-file': 'assistment_test15.csv',\n",
        "    'save-dir': 'save',\n",
        "    'graph-save-dir': '',\n",
        "    'load-dir': '',\n",
        "    'dkt-graph-dir': '',\n",
        "    'dkt-graph': 'dkt-graph',\n",
        "    'model': 'GKT',\n",
        "    'hid-dim': 32,\n",
        "    'emb-dim': 32,\n",
        "    'attn-dim': 32,\n",
        "    'vae-encoder-dim': 32,\n",
        "    'vae-decoder-dim': 32,\n",
        "    'edge-types': 2,\n",
        "    'graph-type': 'MHA',\n",
        "    'dropout': 0,\n",
        "    'bias': True,\n",
        "    'binary': True,\n",
        "    'result-type': 12,\n",
        "    'temp': 0.5,\n",
        "    'hard': False,\n",
        "    'no-factor': False,\n",
        "    'prior': True,\n",
        "    'var': 1,\n",
        "    'epochs': 50,\n",
        "    'batch-size': 128,\n",
        "    'train-ratio': 0.6,\n",
        "    'val-ratio': 0.2,\n",
        "    'shuffle': True,\n",
        "    'lr': 0.001,\n",
        "    'lr-decay': 200,\n",
        "    'gamma': 0.5,\n",
        "    'test': False,\n",
        "    'test-model-dir': ''\n",
        "}"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "4gyrhHDNa2vu",
        "outputId": "5e26bbe3-bd4f-4d6e-d434-9a41be7018e1"
      },
      "source": [
        "import random\n",
        "args['cuda'] = torch.cuda.is_available()\n",
        "args['factor'] = not args['no-factor']\n",
        "\n",
        "random.seed(args['seed'])\n",
        "np.random.seed(args['seed'])\n",
        "torch.manual_seed(args['seed'])\n",
        "\n",
        "if args['cuda']:\n",
        "  torch.cuda.manual_seed(args['seed'])\n",
        "  torch.cuda.manual_seed_all(args['seed'])\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "\n",
        "res_len = 2 if args['binary'] else args['result_type']\n",
        "\n",
        "log = None\n",
        "save_dir = args['save-dir']\n",
        "\n",
        "exp_counter = 0\n",
        "now = datetime.datetime.now()\n",
        "# timestamp = now.isoformat()\n",
        "timestamp = now.strftime('%Y-%m-%d %H-%M-%S')\n",
        "    \n",
        "model_file_name = 'GKT' + '-' + args['graph-type']\n",
        "save_dir = '{}/exp{}/'.format(args['save-dir'], model_file_name + timestamp)\n",
        "if not os.path.exists(save_dir):\n",
        "  os.makedirs(save_dir)\n",
        "meta_file = os.path.join(save_dir, 'metadata.pkl')\n",
        "model_file = os.path.join(save_dir, model_file_name + '.pt')\n",
        "optimizer_file = os.path.join(save_dir, model_file_name + '-Optimizer.pt')\n",
        "scheduler_file = os.path.join(save_dir, model_file_name + '-Scheduler.pt')\n",
        "log_file = os.path.join(save_dir, 'log.txt')\n",
        "log = open(log_file, 'w')\n",
        "pickle.dump({'args': args}, open(meta_file, \"wb\"))\n",
        "\n",
        "dataset_path = os.path.join(args['data-dir'], args['data-file'])\n",
        "dkt_graph_path = os.path.join(args['dkt-graph-dir'], args['dkt-graph'])\n",
        "if not os.path.exists(dkt_graph_path):\n",
        "    dkt_graph_path = None\n",
        "concept_num, graph, train_loader, valid_loader, test_loader = load_dataset(dataset_path, args['batch-size'], args['graph-type'], dkt_graph_path=dkt_graph_path,\n",
        "                                                                           train_ratio=args['train-ratio'], val_ratio=args['val-ratio'], shuffle=args['shuffle'],\n",
        "                                                                           model_type=args['model'], use_cuda=args['cuda'])\n",
        "\n",
        "if args['graph-type'] == 'MHA':\n",
        "  graph_model = MultiHeadAttention(args['edge-types'], concept_num, args['emb-dim'], args['attn-dim'], dropout=args['dropout'])\n",
        "elif args['graph-type'] == 'VAE':\n",
        "  graph_model = VAE(args['emb_dim'], args['vae-encoder-dim'], args['edge-types'], args['vae-decoder-dim'], args['vae-decoder-dim'], concept_num,\n",
        "                          edge_type_num=args['edge-types'], tau=args['temp'], factor=args['factor'], dropout=args['dropout'], bias=args['bias'])\n",
        "  vae_loss = VAELoss(concept_num, edge_type_num=args['edge-types'], prior=args['prior'], var=args['var'])\n",
        "  if args.cuda:\n",
        "      vae_loss = vae_loss.cuda()\n",
        "if args['cuda'] and args['graph-type'] in ['MHA', 'VAE']:\n",
        "  graph_model = graph_model.cuda()\n",
        "model = GKT(concept_num, args['hid-dim'], args['emb-dim'], args['edge-types'], args['graph-type'], graph=graph, graph_model=graph_model,\n",
        "                dropout=args['dropout'], bias=args['bias'], has_cuda=args['cuda'])\n",
        "\n",
        "kt_loss = KTLoss()\n",
        "\n",
        "# build optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=args['lr'])\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=args['lr-decay'], gamma=args['gamma'])\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=args['lr'])\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=args['lr-decay'], gamma=args['gamma'])\n",
        "\n",
        "if args['model'] == 'GKT' and args['prior']:\n",
        "    prior = np.array([0.91, 0.03, 0.03, 0.03])  # TODO: hard coded for now\n",
        "    print(\"Using prior\")\n",
        "    print(prior)\n",
        "    log_prior = torch.FloatTensor(np.log(prior))\n",
        "    log_prior = torch.unsqueeze(log_prior, 0)\n",
        "    log_prior = torch.unsqueeze(log_prior, 0)\n",
        "    log_prior = Variable(log_prior)\n",
        "    if args['cuda']:\n",
        "        log_prior = log_prior.cuda()\n",
        "\n",
        "if args['cuda']:\n",
        "    model = model.cuda()\n",
        "    kt_loss = KTLoss()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-3d38c2e8a28c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mexp_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mnow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;31m# timestamp = now.isoformat()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mtimestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%Y-%m-%d %H-%M-%S'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'datetime' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyKsEN4DfKt-"
      },
      "source": [
        "def train(epoch, best_val_loss):\n",
        "    t = time.time()\n",
        "    loss_train = []\n",
        "    kt_train = []\n",
        "    vae_train = []\n",
        "    auc_train = []\n",
        "    acc_train = []\n",
        "    if graph_model is not None:\n",
        "        graph_model.train()\n",
        "    model.train()\n",
        "    for batch_idx, (features, questions, answers) in enumerate(train_loader):\n",
        "        t1 = time.time()\n",
        "        if args['cuda']:\n",
        "            features, questions, answers = features.cuda(), questions.cuda(), answers.cuda()\n",
        "        ec_list, rec_list, z_prob_list = None, None, None\n",
        "        pred_res, ec_list, rec_list, z_prob_list = model(features, questions)\n",
        "        loss_kt, auc, acc = kt_loss(pred_res, answers)\n",
        "        kt_train.append(float(loss_kt.cpu().detach().numpy()))\n",
        "        if auc != -1 and acc != -1:\n",
        "            auc_train.append(auc)\n",
        "            acc_train.append(acc)\n",
        "\n",
        "        \n",
        "        loss = loss_kt\n",
        "        print('batch idx: ', batch_idx, 'loss kt: ', loss_kt.item(), 'auc: ', auc, 'acc: ', acc, end=' ')\n",
        "        loss_train.append(float(loss.cpu().detach().numpy()))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        del loss\n",
        "        print('cost time: ', str(time.time() - t1))\n",
        "\n",
        "    loss_val = []\n",
        "    kt_val = []\n",
        "    vae_val = []\n",
        "    auc_val = []\n",
        "    acc_val = []\n",
        "\n",
        "    if graph_model is not None:\n",
        "        graph_model.eval()\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (features, questions, answers) in enumerate(valid_loader):\n",
        "            if args['cuda']:\n",
        "                features, questions, answers = features.cuda(), questions.cuda(), answers.cuda()\n",
        "            ec_list, rec_list, z_prob_list = None, None, None\n",
        "            pred_res, ec_list, rec_list, z_prob_list = model(features, questions)\n",
        "\n",
        "            loss_kt, auc, acc = kt_loss(pred_res, answers)\n",
        "            loss_kt = float(loss_kt.cpu().detach().numpy())\n",
        "            kt_val.append(loss_kt)\n",
        "            if auc != -1 and acc != -1:\n",
        "                auc_val.append(auc)\n",
        "                acc_val.append(acc)\n",
        "\n",
        "            loss = loss_kt\n",
        "            loss_val.append(loss)\n",
        "            del loss\n",
        "    \n",
        "    print('Epoch: {:04d}'.format(epoch),\n",
        "              'loss_train: {:.10f}'.format(np.mean(loss_train)),\n",
        "              'auc_train: {:.10f}'.format(np.mean(auc_train)),\n",
        "              'acc_train: {:.10f}'.format(np.mean(acc_train)),\n",
        "              'loss_val: {:.10f}'.format(np.mean(loss_val)),\n",
        "              'auc_val: {:.10f}'.format(np.mean(auc_val)),\n",
        "              'acc_val: {:.10f}'.format(np.mean(acc_val)),\n",
        "              'time: {:.4f}s'.format(time.time() - t))\n",
        "    if args['save-dir'] and np.mean(loss_val) < best_val_loss:\n",
        "        print('Best model so far, saving...')\n",
        "        torch.save(model.state_dict(), model_file)\n",
        "        torch.save(optimizer.state_dict(), optimizer_file)\n",
        "        torch.save(scheduler.state_dict(), scheduler_file)\n",
        "        print('Epoch: {:04d}'.format(epoch),\n",
        "                  'loss_train: {:.10f}'.format(np.mean(loss_train)),\n",
        "                  'auc_train: {:.10f}'.format(np.mean(auc_train)),\n",
        "                  'acc_train: {:.10f}'.format(np.mean(acc_train)),\n",
        "                  'loss_val: {:.10f}'.format(np.mean(loss_val)),\n",
        "                  'auc_val: {:.10f}'.format(np.mean(auc_val)),\n",
        "                  'acc_val: {:.10f}'.format(np.mean(acc_val)),\n",
        "                  'time: {:.4f}s'.format(time.time() - t), file=log)\n",
        "        log.flush()\n",
        "    res = np.mean(loss_val)\n",
        "    del loss_train\n",
        "    del auc_train\n",
        "    del acc_train\n",
        "    del loss_val\n",
        "    del auc_val\n",
        "    del acc_val\n",
        "    gc.collect()\n",
        "    if args['cuda']:\n",
        "        torch.cuda.empty_cache()\n",
        "    return res"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TThUXRqCgf0s",
        "outputId": "267ebae2-15ab-4e23-ccbb-f3999a99a5ca"
      },
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import random\n",
        "import argparse\n",
        "import pickle\n",
        "import os\n",
        "import gc\n",
        "import datetime\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from sklearn.metrics import roc_auc_score\n",
        "def test():\n",
        "    loss_test = []\n",
        "    kt_test = []\n",
        "    vae_test = []\n",
        "    auc_test = []\n",
        "    acc_test = []\n",
        "\n",
        "    if graph_model is not None:\n",
        "        graph_model.eval()\n",
        "    model.eval()\n",
        "    model.load_state_dict(torch.load(model_file))\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (features, questions, answers) in enumerate(test_loader):\n",
        "            if args.cuda:\n",
        "                features, questions, answers = features.cuda(), questions.cuda(), answers.cuda()\n",
        "            ec_list, rec_list, z_prob_list = None, None, None\n",
        "            pred_res, ec_list, rec_list, z_prob_list = model(features, questions)\n",
        "            \n",
        "            loss_kt, auc, acc = kt_loss(pred_res, answers)\n",
        "            loss_kt = float(loss_kt.cpu().detach().numpy())\n",
        "            if auc != -1 and acc != -1:\n",
        "                auc_test.append(auc)\n",
        "                acc_test.append(acc)\n",
        "            kt_test.append(loss_kt)\n",
        "            loss = loss_kt\n",
        "            loss_test.append(loss)\n",
        "            del loss\n",
        "    print('--------------------------------')\n",
        "    print('--------Testing-----------------')\n",
        "    print('--------------------------------')\n",
        "    \n",
        "    print('loss_test: {:.10f}'.format(np.mean(loss_test)),\n",
        "              'auc_test: {:.10f}'.format(np.mean(auc_test)),\n",
        "              'acc_test: {:.10f}'.format(np.mean(acc_test)))\n",
        "    if args['save_dir']:\n",
        "        print('--------------------------------', file=log)\n",
        "        print('--------Testing-----------------', file=log)\n",
        "        print('--------------------------------', file=log)\n",
        "        \n",
        "        print('loss_test: {:.10f}'.format(np.mean(loss_test)),\n",
        "                  'auc_test: {:.10f}'.format(np.mean(auc_test)),\n",
        "                  'acc_test: {:.10f}'.format(np.mean(acc_test)), file=log)\n",
        "        log.flush()\n",
        "    del loss_test\n",
        "    del auc_test\n",
        "    del acc_test\n",
        "    gc.collect()\n",
        "    if args['cuda']:\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "if args['test'] is False:\n",
        "    # Train model\n",
        "    print('start training!')\n",
        "    t_total = time.time()\n",
        "    best_val_loss = np.inf\n",
        "    best_epoch = 0\n",
        "    for epoch in range(args['epochs']):\n",
        "        val_loss = train(epoch, best_val_loss)\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            best_epoch = epoch\n",
        "    print(\"Optimization Finished!\")\n",
        "    print(\"Best Epoch: {:04d}\".format(best_epoch))\n",
        "    if args['save-dir']:\n",
        "        print(\"Best Epoch: {:04d}\".format(best_epoch), file=log)\n",
        "        log.flush()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start training!\n",
            "batch idx:  0 loss kt:  0.7155298590660095 auc:  0.5106289051888073 acc:  0.448 cost time:  2.471405267715454\n",
            "Epoch: 0000 loss_train: 0.7155298591 auc_train: 0.5106289052 acc_train: 0.4480000000 loss_val: 0.7300035954 auc_val: 0.4746738747 acc_val: 0.4561855670 time: 3.0986s\n",
            "Best model so far, saving...\n",
            "batch idx:  0 loss kt:  0.7067127823829651 auc:  0.53248664312234 acc:  0.4736 cost time:  2.4328744411468506\n",
            "Epoch: 0001 loss_train: 0.7067127824 auc_train: 0.5324866431 acc_train: 0.4736000000 loss_val: 0.7227399945 auc_val: 0.4818427547 acc_val: 0.4690721649 time: 3.0563s\n",
            "Best model so far, saving...\n",
            "batch idx:  0 loss kt:  0.7003569602966309 auc:  0.5517635606266413 acc:  0.4976 cost time:  2.4646854400634766\n",
            "Epoch: 0002 loss_train: 0.7003569603 auc_train: 0.5517635606 acc_train: 0.4976000000 loss_val: 0.7214264870 auc_val: 0.4856034787 acc_val: 0.4793814433 time: 3.0793s\n",
            "Best model so far, saving...\n",
            "batch idx:  0 loss kt:  0.6946474313735962 auc:  0.5696708322013946 acc:  0.5152 cost time:  2.4403932094573975\n",
            "Epoch: 0003 loss_train: 0.6946474314 auc_train: 0.5696708322 acc_train: 0.5152000000 loss_val: 0.7201496363 auc_val: 0.4803443413 acc_val: 0.4510309278 time: 3.0675s\n",
            "Best model so far, saving...\n",
            "batch idx:  0 loss kt:  0.6889302730560303 auc:  0.5850708593679254 acc:  0.5344 cost time:  2.5247139930725098\n",
            "Epoch: 0004 loss_train: 0.6889302731 auc_train: 0.5850708594 acc_train: 0.5344000000 loss_val: 0.7153944969 auc_val: 0.4930955459 acc_val: 0.4896907216 time: 3.1500s\n",
            "Best model so far, saving...\n",
            "batch idx:  0 loss kt:  0.6842995882034302 auc:  0.6000294304084035 acc:  0.5632 cost time:  2.535156726837158\n",
            "Epoch: 0005 loss_train: 0.6842995882 auc_train: 0.6000294304 acc_train: 0.5632000000 loss_val: 0.7098537087 auc_val: 0.4939182043 acc_val: 0.5025773196 time: 3.1371s\n",
            "Best model so far, saving...\n",
            "batch idx:  0 loss kt:  0.6803750991821289 auc:  0.6108281264149236 acc:  0.576 cost time:  2.4231622219085693\n",
            "Epoch: 0006 loss_train: 0.6803750992 auc_train: 0.6108281264 acc_train: 0.5760000000 loss_val: 0.7095481753 auc_val: 0.4939475849 acc_val: 0.5025773196 time: 3.0616s\n",
            "Best model so far, saving...\n",
            "batch idx:  0 loss kt:  0.6763406991958618 auc:  0.6189328081137373 acc:  0.6016 cost time:  2.415865182876587\n",
            "Epoch: 0007 loss_train: 0.6763406992 auc_train: 0.6189328081 acc_train: 0.6016000000 loss_val: 0.7105686665 auc_val: 0.4959160888 acc_val: 0.5025773196 time: 3.0451s\n",
            "batch idx:  0 loss kt:  0.6727054715156555 auc:  0.6276374173684687 acc:  0.6048 cost time:  2.430983304977417\n",
            "Epoch: 0008 loss_train: 0.6727054715 auc_train: 0.6276374174 acc_train: 0.6048000000 loss_val: 0.7075194716 auc_val: 0.4971794570 acc_val: 0.5309278351 time: 3.0391s\n",
            "Best model so far, saving...\n",
            "batch idx:  0 loss kt:  0.6689639687538147 auc:  0.6378927827583084 acc:  0.632 cost time:  2.4280145168304443\n",
            "Epoch: 0009 loss_train: 0.6689639688 auc_train: 0.6378927828 acc_train: 0.6320000000 loss_val: 0.7061937451 auc_val: 0.4969150311 acc_val: 0.5180412371 time: 3.0531s\n",
            "Best model so far, saving...\n",
            "batch idx:  0 loss kt:  0.6655434370040894 auc:  0.6461332971112923 acc:  0.6432 cost time:  2.414759397506714\n",
            "Epoch: 0010 loss_train: 0.6655434370 auc_train: 0.6461332971 acc_train: 0.6432000000 loss_val: 0.7039670944 auc_val: 0.4980608767 acc_val: 0.5180412371 time: 3.0624s\n",
            "Best model so far, saving...\n",
            "batch idx:  0 loss kt:  0.6619488000869751 auc:  0.6532192339038304 acc:  0.6496 cost time:  2.409456729888916\n",
            "Epoch: 0011 loss_train: 0.6619488001 auc_train: 0.6532192339 acc_train: 0.6496000000 loss_val: 0.7001326084 auc_val: 0.4987366318 acc_val: 0.5128865979 time: 3.0524s\n",
            "Best model so far, saving...\n",
            "batch idx:  0 loss kt:  0.6584754586219788 auc:  0.6592524676265508 acc:  0.6672 cost time:  2.4323456287384033\n",
            "Epoch: 0012 loss_train: 0.6584754586 auc_train: 0.6592524676 acc_train: 0.6672000000 loss_val: 0.6977972984 auc_val: 0.4992361029 acc_val: 0.5154639175 time: 3.0873s\n",
            "Best model so far, saving...\n",
            "batch idx:  0 loss kt:  0.6556176543235779 auc:  0.6614031513175768 acc:  0.6688 cost time:  2.448479175567627\n",
            "Epoch: 0013 loss_train: 0.6556176543 auc_train: 0.6614031513 acc_train: 0.6688000000 loss_val: 0.6956893802 auc_val: 0.4995299095 acc_val: 0.5283505155 time: 3.0496s\n",
            "Best model so far, saving...\n",
            "batch idx:  0 loss kt:  0.651742696762085 auc:  0.6720999728334692 acc:  0.6736 cost time:  2.3937954902648926\n",
            "Epoch: 0014 loss_train: 0.6517426968 auc_train: 0.6720999728 acc_train: 0.6736000000 loss_val: 0.6970742345 auc_val: 0.4974438829 acc_val: 0.5231958763 time: 3.0092s\n",
            "batch idx:  0 loss kt:  0.6481602787971497 auc:  0.6832382504754142 acc:  0.6784 cost time:  2.425910472869873\n",
            "Epoch: 0015 loss_train: 0.6481602788 auc_train: 0.6832382505 acc_train: 0.6784000000 loss_val: 0.6980009079 auc_val: 0.5098131390 acc_val: 0.5309278351 time: 3.0450s\n",
            "batch idx:  0 loss kt:  0.6446208357810974 auc:  0.6913316127863806 acc:  0.688 cost time:  2.448857069015503\n",
            "Epoch: 0016 loss_train: 0.6446208358 auc_train: 0.6913316128 acc_train: 0.6880000000 loss_val: 0.6962956786 auc_val: 0.5133388177 acc_val: 0.5283505155 time: 3.0626s\n",
            "batch idx:  0 loss kt:  0.6420130133628845 auc:  0.6923390383048085 acc:  0.6832 cost time:  2.4472928047180176\n",
            "Epoch: 0017 loss_train: 0.6420130134 auc_train: 0.6923390383 acc_train: 0.6832000000 loss_val: 0.6946251392 auc_val: 0.5145728053 acc_val: 0.5257731959 time: 3.0846s\n",
            "Best model so far, saving...\n",
            "batch idx:  0 loss kt:  0.6382153630256653 auc:  0.6995494883636693 acc:  0.688 cost time:  2.4853622913360596\n",
            "Epoch: 0018 loss_train: 0.6382153630 auc_train: 0.6995494884 acc_train: 0.6880000000 loss_val: 0.7074250579 auc_val: 0.4967975085 acc_val: 0.5231958763 time: 3.1128s\n",
            "batch idx:  0 loss kt:  0.6349634528160095 auc:  0.7054016118808295 acc:  0.6928 cost time:  2.459132671356201\n",
            "Epoch: 0019 loss_train: 0.6349634528 auc_train: 0.7054016119 acc_train: 0.6928000000 loss_val: 0.7069556117 auc_val: 0.4973557410 acc_val: 0.5309278351 time: 3.0758s\n",
            "batch idx:  0 loss kt:  0.6320562362670898 auc:  0.7078692384315857 acc:  0.6976 cost time:  2.4019298553466797\n",
            "Epoch: 0020 loss_train: 0.6320562363 auc_train: 0.7078692384 acc_train: 0.6976000000 loss_val: 0.7062882781 auc_val: 0.4985015866 acc_val: 0.5257731959 time: 3.0158s\n",
            "batch idx:  0 loss kt:  0.6308241486549377 auc:  0.7075522955718556 acc:  0.6976 cost time:  2.4282853603363037\n",
            "Epoch: 0021 loss_train: 0.6308241487 auc_train: 0.7075522956 acc_train: 0.6976000000 loss_val: 0.7082521915 auc_val: 0.4954166177 acc_val: 0.5231958763 time: 3.0667s\n",
            "batch idx:  0 loss kt:  0.6298279762268066 auc:  0.7086049986416735 acc:  0.6992 cost time:  2.454011917114258\n",
            "Epoch: 0022 loss_train: 0.6298279762 auc_train: 0.7086049986 acc_train: 0.6992000000 loss_val: 0.7084138393 auc_val: 0.4953284757 acc_val: 0.5257731959 time: 3.0971s\n",
            "batch idx:  0 loss kt:  0.628807544708252 auc:  0.7105066558000545 acc:  0.6992 cost time:  2.4736199378967285\n",
            "Epoch: 0023 loss_train: 0.6288075447 auc_train: 0.7105066558 acc_train: 0.6992000000 loss_val: 0.7076328993 auc_val: 0.4963861793 acc_val: 0.5283505155 time: 3.0945s\n",
            "batch idx:  0 loss kt:  0.6274533271789551 auc:  0.7122951190799601 acc:  0.6976 cost time:  2.4250097274780273\n",
            "Epoch: 0024 loss_train: 0.6274533272 auc_train: 0.7122951191 acc_train: 0.6976000000 loss_val: 0.7075235248 auc_val: 0.4965330826 acc_val: 0.5206185567 time: 3.0309s\n",
            "batch idx:  0 loss kt:  0.6260219216346741 auc:  0.7134723354161007 acc:  0.6992 cost time:  2.421212673187256\n",
            "Epoch: 0025 loss_train: 0.6260219216 auc_train: 0.7134723354 acc_train: 0.6992000000 loss_val: 0.7071404457 auc_val: 0.4968856505 acc_val: 0.5257731959 time: 3.0316s\n",
            "batch idx:  0 loss kt:  0.6248173713684082 auc:  0.7149325364484289 acc:  0.7024 cost time:  2.412832021713257\n",
            "Epoch: 0026 loss_train: 0.6248173714 auc_train: 0.7149325364 acc_train: 0.7024000000 loss_val: 0.7061721087 auc_val: 0.4974145023 acc_val: 0.5231958763 time: 3.0533s\n",
            "batch idx:  0 loss kt:  0.6241064667701721 auc:  0.7135742099067283 acc:  0.7008 cost time:  2.488421678543091\n",
            "Epoch: 0027 loss_train: 0.6241064668 auc_train: 0.7135742099 acc_train: 0.7008000000 loss_val: 0.7075234652 auc_val: 0.4957104243 acc_val: 0.5231958763 time: 3.1046s\n",
            "batch idx:  0 loss kt:  0.6229470372200012 auc:  0.7139590690935435 acc:  0.6944 cost time:  2.4522573947906494\n",
            "Epoch: 0028 loss_train: 0.6229470372 auc_train: 0.7139590691 acc_train: 0.6944000000 loss_val: 0.7087526321 auc_val: 0.4940357269 acc_val: 0.5231958763 time: 3.0838s\n",
            "batch idx:  0 loss kt:  0.6215447783470154 auc:  0.716098433396722 acc:  0.6944 cost time:  2.45379376411438\n",
            "Epoch: 0029 loss_train: 0.6215447783 auc_train: 0.7160984334 acc_train: 0.6944000000 loss_val: 0.7016537189 auc_val: 0.5022916912 acc_val: 0.5438144330 time: 3.0864s\n",
            "batch idx:  0 loss kt:  0.6204976439476013 auc:  0.7172982885085575 acc:  0.696 cost time:  2.4380688667297363\n",
            "Epoch: 0030 loss_train: 0.6204976439 auc_train: 0.7172982885 acc_train: 0.6960000000 loss_val: 0.7013542056 auc_val: 0.5018803620 acc_val: 0.5360824742 time: 3.0564s\n",
            "batch idx:  0 loss kt:  0.6193886995315552 auc:  0.7184189079054605 acc:  0.696 cost time:  2.401228666305542\n",
            "Epoch: 0031 loss_train: 0.6193886995 auc_train: 0.7184189079 acc_train: 0.6960000000 loss_val: 0.6983767748 auc_val: 0.5045833823 acc_val: 0.5360824742 time: 3.0483s\n",
            "batch idx:  0 loss kt:  0.6181354522705078 auc:  0.719664040568686 acc:  0.6928 cost time:  2.41797137260437\n",
            "Epoch: 0032 loss_train: 0.6181354523 auc_train: 0.7196640406 acc_train: 0.6928000000 loss_val: 0.6977569461 auc_val: 0.5047890469 acc_val: 0.5360824742 time: 3.0649s\n",
            "batch idx:  0 loss kt:  0.6166247129440308 auc:  0.7215770171149144 acc:  0.6928 cost time:  2.4100501537323\n",
            "Epoch: 0033 loss_train: 0.6166247129 auc_train: 0.7215770171 acc_train: 0.6928000000 loss_val: 0.6981299520 auc_val: 0.5033787754 acc_val: 0.5438144330 time: 3.0551s\n",
            "batch idx:  0 loss kt:  0.6152565479278564 auc:  0.7230145793715476 acc:  0.6928 cost time:  2.436361074447632\n",
            "Epoch: 0034 loss_train: 0.6152565479 auc_train: 0.7230145794 acc_train: 0.6928000000 loss_val: 0.6973077655 auc_val: 0.5043483371 acc_val: 0.5438144330 time: 3.0499s\n",
            "batch idx:  0 loss kt:  0.614325225353241 auc:  0.7231730508014127 acc:  0.6944 cost time:  2.4622280597686768\n",
            "Epoch: 0035 loss_train: 0.6143252254 auc_train: 0.7231730508 acc_train: 0.6944000000 loss_val: 0.6949938536 auc_val: 0.5130743918 acc_val: 0.5386597938 time: 3.0668s\n",
            "batch idx:  0 loss kt:  0.6127399206161499 auc:  0.7249388753056235 acc:  0.6976 cost time:  2.461132764816284\n",
            "Epoch: 0036 loss_train: 0.6127399206 auc_train: 0.7249388753 acc_train: 0.6976000000 loss_val: 0.6960443854 auc_val: 0.5088729580 acc_val: 0.5386597938 time: 3.0879s\n",
            "batch idx:  0 loss kt:  0.6114664077758789 auc:  0.7273046273657521 acc:  0.696 cost time:  2.4697792530059814\n",
            "Epoch: 0037 loss_train: 0.6114664078 auc_train: 0.7273046274 acc_train: 0.6960000000 loss_val: 0.6984176636 auc_val: 0.5088435774 acc_val: 0.5386597938 time: 3.0961s\n",
            "batch idx:  0 loss kt:  0.61030113697052 auc:  0.7283686498234175 acc:  0.696 cost time:  2.471249580383301\n",
            "Epoch: 0038 loss_train: 0.6103011370 auc_train: 0.7283686498 acc_train: 0.6960000000 loss_val: 0.6985112429 auc_val: 0.5070807380 acc_val: 0.5412371134 time: 3.0942s\n",
            "batch idx:  0 loss kt:  0.6088468432426453 auc:  0.7300552386126958 acc:  0.696 cost time:  2.4677534103393555\n",
            "Epoch: 0039 loss_train: 0.6088468432 auc_train: 0.7300552386 acc_train: 0.6960000000 loss_val: 0.6981260180 auc_val: 0.5082559643 acc_val: 0.5412371134 time: 3.1003s\n",
            "batch idx:  0 loss kt:  0.6075478792190552 auc:  0.7322059223037218 acc:  0.696 cost time:  2.429671049118042\n",
            "Epoch: 0040 loss_train: 0.6075478792 auc_train: 0.7322059223 acc_train: 0.6960000000 loss_val: 0.6977536082 auc_val: 0.5096956164 acc_val: 0.5412371134 time: 3.0424s\n",
            "batch idx:  0 loss kt:  0.6060965657234192 auc:  0.7337793172145252 acc:  0.6992 cost time:  2.515371084213257\n",
            "Epoch: 0041 loss_train: 0.6060965657 auc_train: 0.7337793172 acc_train: 0.6992000000 loss_val: 0.6974003315 auc_val: 0.5088141967 acc_val: 0.5489690722 time: 3.1652s\n",
            "batch idx:  0 loss kt:  0.6050818562507629 auc:  0.734809381508648 acc:  0.6976 cost time:  2.4702649116516113\n",
            "Epoch: 0042 loss_train: 0.6050818563 auc_train: 0.7348093815 acc_train: 0.6976000000 loss_val: 0.6912726760 auc_val: 0.5130156305 acc_val: 0.5567010309 time: 3.1058s\n",
            "Best model so far, saving...\n",
            "batch idx:  0 loss kt:  0.603186845779419 auc:  0.7376618672462193 acc:  0.7024 cost time:  2.456859588623047\n",
            "Epoch: 0043 loss_train: 0.6031868458 auc_train: 0.7376618672 acc_train: 0.7024000000 loss_val: 0.6985523105 auc_val: 0.5104595135 acc_val: 0.5438144330 time: 3.0725s\n",
            "batch idx:  0 loss kt:  0.6018531322479248 auc:  0.7391560264420899 acc:  0.7056 cost time:  2.4143736362457275\n",
            "Epoch: 0044 loss_train: 0.6018531322 auc_train: 0.7391560264 acc_train: 0.7056000000 loss_val: 0.6964815259 auc_val: 0.5132800564 acc_val: 0.5463917526 time: 3.0421s\n",
            "batch idx:  0 loss kt:  0.6003789305686951 auc:  0.7410010866612334 acc:  0.7056 cost time:  2.4540045261383057\n",
            "Epoch: 0045 loss_train: 0.6003789306 auc_train: 0.7410010867 acc_train: 0.7056000000 loss_val: 0.6961222291 auc_val: 0.5138970502 acc_val: 0.5463917526 time: 3.0741s\n",
            "batch idx:  0 loss kt:  0.5994398593902588 auc:  0.7416236529928462 acc:  0.7024 cost time:  2.4229114055633545\n",
            "Epoch: 0046 loss_train: 0.5994398594 auc_train: 0.7416236530 acc_train: 0.7024000000 loss_val: 0.6897471547 auc_val: 0.5164237866 acc_val: 0.5567010309 time: 3.0463s\n",
            "Best model so far, saving...\n",
            "batch idx:  0 loss kt:  0.5977768898010254 auc:  0.7438988499501946 acc:  0.704 cost time:  2.428903102874756\n",
            "Epoch: 0047 loss_train: 0.5977768898 auc_train: 0.7438988500 acc_train: 0.7040000000 loss_val: 0.6891433597 auc_val: 0.5170407804 acc_val: 0.5618556701 time: 3.0364s\n",
            "Best model so far, saving...\n",
            "batch idx:  0 loss kt:  0.5958185791969299 auc:  0.7469098071176312 acc:  0.7088 cost time:  2.4248130321502686\n",
            "Epoch: 0048 loss_train: 0.5958185792 auc_train: 0.7469098071 acc_train: 0.7088000000 loss_val: 0.6948109865 auc_val: 0.5134857210 acc_val: 0.5567010309 time: 3.0582s\n",
            "batch idx:  0 loss kt:  0.5941383838653564 auc:  0.7505093724531378 acc:  0.7104 cost time:  2.4084911346435547\n",
            "Epoch: 0049 loss_train: 0.5941383839 auc_train: 0.7505093725 acc_train: 0.7104000000 loss_val: 0.6964161396 auc_val: 0.5122811141 acc_val: 0.5515463918 time: 3.0355s\n",
            "Optimization Finished!\n",
            "Best Epoch: 0047\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6qR0JVslIlZ"
      },
      "source": [
        "torch.save(model, '/content/model_50.pt')"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZGa9oRSlmX4"
      },
      "source": [
        "new_model = torch.load('/content/model_50.pt')"
      ],
      "execution_count": 11,
      "outputs": []
    }
  ]
}